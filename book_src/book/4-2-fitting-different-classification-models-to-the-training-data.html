<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="4.2 Fitting Different Classification Models to the Training Data | R Code Companion for the Textbook Introduction to Data Mining" />
<meta property="og:type" content="book" />


<meta property="og:description" content="This book contains documented R examples to accompany several chapters of the popular data mining text book Introduction to Data Mining by Pang-Ning Tan, Michael Steinbach and Vipin Kumar (2006 or 2017 edition)." />


<meta name="author" content="Michael Hahsler" />

<meta name="date" content="2021-07-09" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book contains documented R examples to accompany several chapters of the popular data mining text book Introduction to Data Mining by Pang-Ning Tan, Michael Steinbach and Vipin Kumar (2006 or 2017 edition).">

<title>4.2 Fitting Different Classification Models to the Training Data | R Code Companion for the Textbook Introduction to Data Mining</title>

<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap/js/bootstrap.min.js"></script>
<script src="libs/bootstrap/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation/tabsets.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider/jquery.nouislider.min.js"></script>
<link href="libs/selectize/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize/selectize.min.js"></script>
<link href="libs/vis/vis.css" rel="stylesheet" />
<script src="libs/vis/vis.min.js"></script>
<script src="libs/visNetwork-binding/visNetwork.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li><a href="1-introduction.html#introduction"><span class="toc-section-number">1</span> Introduction</a>
<ul>
<li><a href="1-1-data-manipulation-with-tidyverse.html#data-manipulation-with-tidyverse"><span class="toc-section-number">1.1</span> Data Manipulation with Tidyverse</a></li>
<li><a href="1-2-visualization-with-ggplot2.html#visualization-with-ggplot2"><span class="toc-section-number">1.2</span> Visualization with ggplot2</a></li>
</ul></li>
<li><a href="2-data.html#data"><span class="toc-section-number">2</span> Data</a>
<ul>
<li><a href="2-1-the-iris-dataset.html#the-iris-dataset"><span class="toc-section-number">2.1</span> The Iris Dataset</a></li>
<li><a href="2-2-data-quality.html#data-quality"><span class="toc-section-number">2.2</span> Data Quality</a></li>
<li><a href="2-3-aggregation.html#aggregation"><span class="toc-section-number">2.3</span> Aggregation</a></li>
<li><a href="2-4-sampling.html#sampling"><span class="toc-section-number">2.4</span> Sampling</a>
<ul>
<li><a href="2-4-sampling.html#random-sampling"><span class="toc-section-number">2.4.1</span> Random Sampling</a></li>
<li><a href="2-4-sampling.html#stratified-sampling"><span class="toc-section-number">2.4.2</span> Stratified Sampling</a></li>
</ul></li>
<li><a href="2-5-features.html#features"><span class="toc-section-number">2.5</span> Features</a>
<ul>
<li><a href="2-5-features.html#dimensionality-reduction"><span class="toc-section-number">2.5.1</span> Dimensionality Reduction</a></li>
<li><a href="2-5-features.html#feature-selection"><span class="toc-section-number">2.5.2</span> Feature Selection</a></li>
<li><a href="2-5-features.html#discretize-features"><span class="toc-section-number">2.5.3</span> Discretize Features</a></li>
<li><a href="2-5-features.html#standardize-data-z-scores"><span class="toc-section-number">2.5.4</span> Standardize Data (Z-Scores)</a></li>
</ul></li>
<li><a href="2-6-proximities-similarities-and-distances.html#proximities-similarities-and-distances"><span class="toc-section-number">2.6</span> Proximities: Similarities and Distances</a>
<ul>
<li><a href="2-6-proximities-similarities-and-distances.html#minkowsky-distances"><span class="toc-section-number">2.6.1</span> Minkowsky Distances</a></li>
<li><a href="2-6-proximities-similarities-and-distances.html#distances-for-binary-data"><span class="toc-section-number">2.6.2</span> Distances for Binary Data</a></li>
<li><a href="2-6-proximities-similarities-and-distances.html#distances-for-mixed-data"><span class="toc-section-number">2.6.3</span> Distances for Mixed Data</a></li>
<li><a href="2-6-proximities-similarities-and-distances.html#additional-proximity-measures-available-in-package-proxy"><span class="toc-section-number">2.6.4</span> Additional proximity Measures Available in Package proxy</a></li>
</ul></li>
<li><a href="2-7-relationships-between-features.html#relationships-between-features"><span class="toc-section-number">2.7</span> Relationships Between Features</a>
<ul>
<li><a href="2-7-relationships-between-features.html#correlation"><span class="toc-section-number">2.7.1</span> Correlation</a></li>
<li><a href="2-7-relationships-between-features.html#rank-correlation"><span class="toc-section-number">2.7.2</span> Rank Correlation</a></li>
<li><a href="2-7-relationships-between-features.html#relationship-between-nominal-and-ordinal-features"><span class="toc-section-number">2.7.3</span> Relationship Between Nominal and Ordinal Features</a></li>
</ul></li>
<li><a href="2-8-density-estimation.html#density-estimation"><span class="toc-section-number">2.8</span> Density Estimation</a></li>
<li><a href="2-9-exploring-data.html#exploring-data"><span class="toc-section-number">2.9</span> Exploring Data</a>
<ul>
<li><a href="2-9-exploring-data.html#basic-statistics"><span class="toc-section-number">2.9.1</span> Basic statistics</a></li>
<li><a href="2-9-exploring-data.html#tabulate-data"><span class="toc-section-number">2.9.2</span> Tabulate data</a></li>
<li><a href="2-9-exploring-data.html#percentiles-quantiles"><span class="toc-section-number">2.9.3</span> Percentiles (Quantiles)</a></li>
</ul></li>
<li><a href="2-10-visualization.html#visualization"><span class="toc-section-number">2.10</span> Visualization</a>
<ul>
<li><a href="2-10-visualization.html#histogram"><span class="toc-section-number">2.10.1</span> Histogram</a></li>
<li><a href="2-10-visualization.html#boxplot"><span class="toc-section-number">2.10.2</span> Boxplot</a></li>
<li><a href="2-10-visualization.html#scatter-plot"><span class="toc-section-number">2.10.3</span> Scatter plot</a></li>
<li><a href="2-10-visualization.html#scatter-plot-matrix"><span class="toc-section-number">2.10.4</span> Scatter Plot Matrix</a></li>
<li><a href="2-10-visualization.html#data-matrix-visualization"><span class="toc-section-number">2.10.5</span> Data Matrix Visualization</a></li>
<li><a href="2-10-visualization.html#correlation-matrix"><span class="toc-section-number">2.10.6</span> Correlation Matrix</a></li>
<li><a href="2-10-visualization.html#parallel-coordinates-plot"><span class="toc-section-number">2.10.7</span> Parallel Coordinates Plot</a></li>
</ul></li>
</ul></li>
<li><a href="3-classification-basic-concepts-and-techniques.html#classification-basic-concepts-and-techniques"><span class="toc-section-number">3</span> Classification: Basic Concepts and Techniques</a>
<ul>
<li><a href="3-1-the-zoo-dataset.html#the-zoo-dataset"><span class="toc-section-number">3.1</span> The Zoo Dataset</a></li>
<li><a href="3-2-decision-trees.html#decision-trees"><span class="toc-section-number">3.2</span> Decision Trees</a>
<ul>
<li><a href="3-2-decision-trees.html#create-tree-with-default-settings-uses-pre-pruning"><span class="toc-section-number">3.2.1</span> Create Tree With Default Settings (uses pre-pruning)</a></li>
<li><a href="3-2-decision-trees.html#create-a-full-tree"><span class="toc-section-number">3.2.2</span> Create a Full Tree</a></li>
<li><a href="3-2-decision-trees.html#make-predictions-for-new-data"><span class="toc-section-number">3.2.3</span> Make Predictions for New Data</a></li>
</ul></li>
<li><a href="3-3-model-evaluation-with-caret.html#model-evaluation-with-caret"><span class="toc-section-number">3.3</span> Model Evaluation with Caret</a>
<ul>
<li><a href="3-3-model-evaluation-with-caret.html#hold-out-test-data"><span class="toc-section-number">3.3.1</span> Hold out Test Data</a></li>
<li><a href="3-3-model-evaluation-with-caret.html#learn-a-model-and-tune-hyperparameters-on-the-training-data"><span class="toc-section-number">3.3.2</span> Learn a Model and Tune Hyperparameters on the Training Data</a></li>
</ul></li>
<li><a href="3-4-testing-confusion-matrix-and-confidence-interval-for-accuracy.html#testing-confusion-matrix-and-confidence-interval-for-accuracy"><span class="toc-section-number">3.4</span> Testing: Confusion Matrix and Confidence Interval for Accuracy</a></li>
<li><a href="3-5-model-comparison.html#model-comparison"><span class="toc-section-number">3.5</span> Model Comparison</a></li>
<li><a href="3-6-feature-selection-and-feature-preparation.html#feature-selection-and-feature-preparation"><span class="toc-section-number">3.6</span> Feature Selection and Feature Preparation</a>
<ul>
<li><a href="3-6-feature-selection-and-feature-preparation.html#univariate-feature-importance-score"><span class="toc-section-number">3.6.1</span> Univariate Feature Importance Score</a></li>
<li><a href="3-6-feature-selection-and-feature-preparation.html#feature-subset-selection"><span class="toc-section-number">3.6.2</span> Feature Subset Selection</a></li>
<li><a href="3-6-feature-selection-and-feature-preparation.html#using-dummy-variables-for-factors"><span class="toc-section-number">3.6.3</span> Using Dummy Variables for Factors</a></li>
</ul></li>
<li><a href="3-7-class-imbalance.html#class-imbalance"><span class="toc-section-number">3.7</span> Class Imbalance</a>
<ul>
<li><a href="3-7-class-imbalance.html#option-1-use-the-data-as-is-and-hope-for-the-best"><span class="toc-section-number">3.7.1</span> Option 1: Use the Data As Is and Hope For The Best</a></li>
<li><a href="3-7-class-imbalance.html#option-2-balance-data-with-resampling"><span class="toc-section-number">3.7.2</span> Option 2: Balance Data With Resampling</a></li>
<li><a href="3-7-class-imbalance.html#option-3-build-a-larger-tree-and-use-predicted-probabilities"><span class="toc-section-number">3.7.3</span> Option 3: Build A Larger Tree and use Predicted Probabilities</a></li>
<li><a href="3-7-class-imbalance.html#option-4-use-a-cost-sensitive-classifier"><span class="toc-section-number">3.7.4</span> Option 4: Use a Cost-Sensitive Classifier</a></li>
</ul></li>
</ul></li>
<li><a href="4-classification-alternative-techniques.html#classification-alternative-techniques"><span class="toc-section-number">4</span> Classification: Alternative Techniques</a>
<ul>
<li><a href="4-1-training-and-test-data.html#training-and-test-data"><span class="toc-section-number">4.1</span> Training and Test Data</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#fitting-different-classification-models-to-the-training-data"><span class="toc-section-number">4.2</span> Fitting Different Classification Models to the Training Data</a>
<ul>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#conditional-inference-tree-decision-tree"><span class="toc-section-number">4.2.1</span> Conditional Inference Tree (Decision Tree)</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#c-4.5-decision-tree"><span class="toc-section-number">4.2.2</span> C 4.5 Decision Tree</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#k-nearest-neighbors"><span class="toc-section-number">4.2.3</span> K-Nearest Neighbors</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#part-rule-based-classifier"><span class="toc-section-number">4.2.4</span> PART (Rule-based classifier)</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#linear-support-vector-machines"><span class="toc-section-number">4.2.5</span> Linear Support Vector Machines</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#random-forest"><span class="toc-section-number">4.2.6</span> Random Forest</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#gradient-boosted-decision-trees-xgboost"><span class="toc-section-number">4.2.7</span> Gradient Boosted Decision Trees (xgboost)</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#artificial-neural-network"><span class="toc-section-number">4.2.8</span> Artificial Neural Network</a></li>
</ul></li>
<li><a href="4-3-comparing-models.html#comparing-models"><span class="toc-section-number">4.3</span> Comparing Models</a></li>
<li><a href="4-4-applying-the-chosen-model-to-the-test-data.html#applying-the-chosen-model-to-the-test-data"><span class="toc-section-number">4.4</span> Applying the Chosen Model to the Test Data</a></li>
<li><a href="4-5-decision-boundaries.html#decision-boundaries"><span class="toc-section-number">4.5</span> Decision Boundaries</a>
<ul>
<li><a href="4-5-decision-boundaries.html#iris-dataset"><span class="toc-section-number">4.5.1</span> Iris Dataset</a></li>
<li><a href="4-5-decision-boundaries.html#circle-dataset"><span class="toc-section-number">4.5.2</span> Circle Dataset</a></li>
</ul></li>
<li><a href="4-6-more-information.html#more-information"><span class="toc-section-number">4.6</span> More Information</a></li>
</ul></li>
<li><a href="5-association-analysis-basic-concepts-and-algorithms.html#association-analysis-basic-concepts-and-algorithms"><span class="toc-section-number">5</span> Association Analysis: Basic Concepts and Algorithms</a>
<ul>
<li><a href="5-1-the-arules-package.html#the-arules-package"><span class="toc-section-number">5.1</span> The arules Package</a></li>
<li><a href="5-2-transactions.html#transactions"><span class="toc-section-number">5.2</span> Transactions</a>
<ul>
<li><a href="5-2-transactions.html#create-transactions"><span class="toc-section-number">5.2.1</span> Create Transactions</a></li>
<li><a href="5-2-transactions.html#inspect-transactions"><span class="toc-section-number">5.2.2</span> Inspect Transactions</a></li>
<li><a href="5-2-transactions.html#vertical-layout-transaction-id-lists"><span class="toc-section-number">5.2.3</span> Vertical Layout (Transaction ID Lists)</a></li>
</ul></li>
<li><a href="5-3-frequent-itemsets.html#frequent-itemsets"><span class="toc-section-number">5.3</span> Frequent Itemsets</a>
<ul>
<li><a href="5-3-frequent-itemsets.html#mine-frequent-itemsets"><span class="toc-section-number">5.3.1</span> Mine Frequent Itemsets</a></li>
<li><a href="5-3-frequent-itemsets.html#concise-representation-of-itemsets"><span class="toc-section-number">5.3.2</span> Concise Representation of Itemsets</a></li>
</ul></li>
<li><a href="5-4-association-rules.html#association-rules"><span class="toc-section-number">5.4</span> Association Rules</a>
<ul>
<li><a href="5-4-association-rules.html#mine-association-rules"><span class="toc-section-number">5.4.1</span> Mine Association Rules</a></li>
<li><a href="5-4-association-rules.html#calculate-additional-interest-measures"><span class="toc-section-number">5.4.2</span> Calculate Additional Interest Measures</a></li>
<li><a href="5-4-association-rules.html#mine-using-templates"><span class="toc-section-number">5.4.3</span> Mine Using Templates</a></li>
</ul></li>
<li><a href="5-5-association-rule-visualization.html#association-rule-visualization"><span class="toc-section-number">5.5</span> Association Rule Visualization</a></li>
<li><a href="5-6-interactive-visualizations.html#interactive-visualizations"><span class="toc-section-number">5.6</span> Interactive Visualizations</a>
<ul>
<li><a href="5-6-interactive-visualizations.html#interactive-inspect-with-sorting-filtering-and-paging"><span class="toc-section-number">5.6.1</span> Interactive Inspect With Sorting, Filtering and Paging</a></li>
<li><a href="5-6-interactive-visualizations.html#scatter-plot-1"><span class="toc-section-number">5.6.2</span> Scatter Plot</a></li>
<li><a href="5-6-interactive-visualizations.html#matrix-visualization"><span class="toc-section-number">5.6.3</span> Matrix Visualization</a></li>
<li><a href="5-6-interactive-visualizations.html#visualization-as-graph"><span class="toc-section-number">5.6.4</span> Visualization as Graph</a></li>
<li><a href="5-6-interactive-visualizations.html#interactive-rule-explorer"><span class="toc-section-number">5.6.5</span> Interactive Rule Explorer</a></li>
</ul></li>
</ul></li>
<li><a href="6-association-analysis-advanced-concepts.html#association-analysis-advanced-concepts"><span class="toc-section-number">6</span> Association Analysis: Advanced Concepts</a></li>
<li><a href="7-clustering-analysis.html#clustering-analysis"><span class="toc-section-number">7</span> Clustering Analysis</a>
<ul>
<li><a href="7-1-data-preparation.html#data-preparation"><span class="toc-section-number">7.1</span> Data Preparation</a>
<ul>
<li><a href="7-1-data-preparation.html#data-cleaning"><span class="toc-section-number">7.1.1</span> Data cleaning</a></li>
<li><a href="7-1-data-preparation.html#scale-data"><span class="toc-section-number">7.1.2</span> Scale data</a></li>
</ul></li>
<li><a href="7-2-clustering-methods.html#clustering-methods"><span class="toc-section-number">7.2</span> Clustering methods</a>
<ul>
<li><a href="7-2-clustering-methods.html#k-means-clustering"><span class="toc-section-number">7.2.1</span> k-means Clustering</a></li>
<li><a href="7-2-clustering-methods.html#hierarchical-clustering"><span class="toc-section-number">7.2.2</span> Hierarchical Clustering</a></li>
<li><a href="7-2-clustering-methods.html#density-based-clustering-with-dbscan"><span class="toc-section-number">7.2.3</span> Density-based clustering with DBSCAN</a></li>
<li><a href="7-2-clustering-methods.html#partitioning-around-medoids-pam"><span class="toc-section-number">7.2.4</span> Partitioning Around Medoids (PAM)</a></li>
<li><a href="7-2-clustering-methods.html#gaussian-mixture-models"><span class="toc-section-number">7.2.5</span> Gaussian Mixture Models</a></li>
<li><a href="7-2-clustering-methods.html#spectral-clustering"><span class="toc-section-number">7.2.6</span> Spectral clustering</a></li>
<li><a href="7-2-clustering-methods.html#fuzzy-c-means-clustering"><span class="toc-section-number">7.2.7</span> Fuzzy C-Means Clustering</a></li>
</ul></li>
<li><a href="7-3-internal-cluster-validation.html#internal-cluster-validation"><span class="toc-section-number">7.3</span> Internal Cluster Validation</a>
<ul>
<li><a href="7-3-internal-cluster-validation.html#compare-the-clustering-quality"><span class="toc-section-number">7.3.1</span> Compare the Clustering Quality</a></li>
<li><a href="7-3-internal-cluster-validation.html#silhouette-plot"><span class="toc-section-number">7.3.2</span> Silhouette plot</a></li>
<li><a href="7-3-internal-cluster-validation.html#find-optimal-number-of-clusters-for-k-means"><span class="toc-section-number">7.3.3</span> Find Optimal Number of Clusters for k-means</a></li>
<li><a href="7-3-internal-cluster-validation.html#visualizing-the-distance-matrix"><span class="toc-section-number">7.3.4</span> Visualizing the Distance Matrix</a></li>
</ul></li>
<li><a href="7-4-external-cluster-validation.html#external-cluster-validation"><span class="toc-section-number">7.4</span> External Cluster Validation</a></li>
<li><a href="7-5-advanced-data-preparation-for-clustering.html#advanced-data-preparation-for-clustering"><span class="toc-section-number">7.5</span> Advanced Data Preparation for Clustering</a>
<ul>
<li><a href="7-5-advanced-data-preparation-for-clustering.html#outlier-removal"><span class="toc-section-number">7.5.1</span> Outlier Removal</a></li>
<li><a href="7-5-advanced-data-preparation-for-clustering.html#clustering-tendency"><span class="toc-section-number">7.5.2</span> Clustering Tendency</a></li>
</ul></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="fitting-different-classification-models-to-the-training-data" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Fitting Different Classification Models to the Training Data</h2>
<p>Create a fixed sampling scheme (10-folds) so we can compare the fitted models
later.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb384-1" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">createFolds</span>(Zoo_train<span class="sc">$</span>type, <span class="at">k =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>The fixed folds are used in <code>train()</code> with the argument
<code>trControl = trainControl(method = "cv", indexOut = train_index))</code>. If you
don’t need fixed folds, then remove <code>indexOut = train_index</code> in the code below.</p>
<p>For help with building models in caret see: <code>? train</code></p>
<p><strong>Note:</strong> Be careful if you have many <code>NA</code> values in your data. <code>train()</code>
and cross-validation many fail in some cases. If that is the case then you
can remove features (columns) which have many <code>NA</code>s, omit <code>NA</code>s using
<code>na.omit()</code> or use imputation to replace them with reasonable
values (e.g., by the feature mean or via kNN). Highly imbalanced datasets are also problematic since there is a chance that a fold does
not contain examples of each class leading to a hard to understand error message.</p>
<div id="conditional-inference-tree-decision-tree" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Conditional Inference Tree (Decision Tree)</h3>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb385-1" aria-hidden="true" tabindex="-1"></a>ctreeFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb385-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb385-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;ctree&quot;</span>,</span>
<span id="cb385-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb385-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb385-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb385-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb385-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb385-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index))</span>
<span id="cb385-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb385-6" aria-hidden="true" tabindex="-1"></a>ctreeFit</span></code></pre></div>
<pre><code>## Conditional Inference Tree 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 75, 76, 74, 74, 76, 74, ... 
## Resampling results across tuning parameters:
## 
##   mincriterion  Accuracy  Kappa
##   0.010         0.808     0.747
##   0.255         0.808     0.747
##   0.500         0.808     0.747
##   0.745         0.808     0.747
##   0.990         0.808     0.747
## 
## Accuracy was used to select the optimal model
##  using the largest value.
## The final value used for the model was mincriterion
##  = 0.99.</code></pre>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb387-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ctreeFit<span class="sc">$</span>finalModel)</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-150-1.png" width="672" /></p>
<p>The final model can be directly used for predict()</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb388-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(ctreeFit, <span class="fu">head</span>(Zoo_test))</span></code></pre></div>
<pre><code>## [1] mammal        mollusc.et.al bird         
## [4] mammal        mollusc.et.al bird         
## 7 Levels: mammal bird reptile fish ... mollusc.et.al</code></pre>
</div>
<div id="c-4.5-decision-tree" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> C 4.5 Decision Tree</h3>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RWeka)</span>
<span id="cb390-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-2" aria-hidden="true" tabindex="-1"></a>C45Fit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb390-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;J48&quot;</span>,</span>
<span id="cb390-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb390-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb390-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index))</span>
<span id="cb390-7"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb390-7" aria-hidden="true" tabindex="-1"></a>C45Fit</span></code></pre></div>
<pre><code>## C4.5-like Trees 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 76, 73, 74, 74, 76, 76, ... 
## Resampling results across tuning parameters:
## 
##   C      M  Accuracy  Kappa
##   0.010  1  0.978     0.971
##   0.010  2  0.978     0.971
##   0.010  3  0.978     0.971
##   0.010  4  0.907     0.879
##   0.010  5  0.918     0.893
##   0.133  1  0.978     0.971
##   0.133  2  0.978     0.971
##   0.133  3  0.978     0.971
##   0.133  4  0.907     0.879
##   0.133  5  0.918     0.893
##   0.255  1  0.989     0.985
##   0.255  2  0.989     0.985
##   0.255  3  0.978     0.971
##   0.255  4  0.907     0.879
##   0.255  5  0.918     0.893
##   0.378  1  0.989     0.985
##   0.378  2  0.989     0.985
##   0.378  3  0.978     0.971
##   0.378  4  0.907     0.879
##   0.378  5  0.918     0.893
##   0.500  1  0.989     0.985
##   0.500  2  0.989     0.985
##   0.500  3  0.978     0.971
##   0.500  4  0.907     0.879
##   0.500  5  0.918     0.893
## 
## Accuracy was used to select the optimal model
##  using the largest value.
## The final values used for the model were C = 0.255
##  and M = 1.</code></pre>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb392-1" aria-hidden="true" tabindex="-1"></a>C45Fit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## J48 pruned tree
## ------------------
## 
## feathersTRUE &lt;= 0
## |   milkTRUE &lt;= 0
## |   |   toothedTRUE &lt;= 0
## |   |   |   airborneTRUE &lt;= 0
## |   |   |   |   predatorTRUE &lt;= 0
## |   |   |   |   |   legs &lt;= 2: mollusc.et.al (2.0)
## |   |   |   |   |   legs &gt; 2: insect (2.0)
## |   |   |   |   predatorTRUE &gt; 0: mollusc.et.al (6.0)
## |   |   |   airborneTRUE &gt; 0: insect (5.0)
## |   |   toothedTRUE &gt; 0
## |   |   |   finsTRUE &lt;= 0
## |   |   |   |   aquaticTRUE &lt;= 0: reptile (3.0)
## |   |   |   |   aquaticTRUE &gt; 0
## |   |   |   |   |   eggsTRUE &lt;= 0: reptile (1.0)
## |   |   |   |   |   eggsTRUE &gt; 0: amphibian (4.0)
## |   |   |   finsTRUE &gt; 0: fish (11.0)
## |   milkTRUE &gt; 0: mammal (33.0)
## feathersTRUE &gt; 0: bird (16.0)
## 
## Number of Leaves  :  10
## 
## Size of the tree :   19</code></pre>
</div>
<div id="k-nearest-neighbors" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> K-Nearest Neighbors</h3>
<p><strong>Note:</strong> kNN uses Euclidean distance, so data should be standardized (scaled) first.
Here legs are measured between 0 and 6 while all other variables are between
0 and 1. Scaling can be directly performed as preprocessing in <code>train</code> using the parameter
<code>preProcess = "scale"</code>.</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-1" aria-hidden="true" tabindex="-1"></a>knnFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb394-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb394-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb394-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">preProcess =</span> <span class="st">&quot;scale&quot;</span>,</span>
<span id="cb394-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb394-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid=</span><span class="fu">data.frame</span>(<span class="at">k =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>),</span>
<span id="cb394-7"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index))</span>
<span id="cb394-8"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb394-8" aria-hidden="true" tabindex="-1"></a>knnFit</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## Pre-processing: scaled (16) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 74, 73, 76, 74, 74, 75, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy  Kappa
##    1  1.000     1.000
##    2  0.978     0.971
##    3  0.967     0.957
##    4  0.943     0.926
##    5  0.965     0.954
##    6  0.916     0.891
##    7  0.883     0.850
##    8  0.872     0.835
##    9  0.883     0.848
##   10  0.908     0.881
## 
## Accuracy was used to select the optimal model
##  using the largest value.
## The final value used for the model was k = 1.</code></pre>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb396-1" aria-hidden="true" tabindex="-1"></a>knnFit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## 1-nearest neighbor model
## Training set outcome distribution:
## 
##        mammal          bird       reptile 
##            33            16             4 
##          fish     amphibian        insect 
##            11             4             7 
## mollusc.et.al 
##             8</code></pre>
</div>
<div id="part-rule-based-classifier" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> PART (Rule-based classifier)</h3>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb398-1" aria-hidden="true" tabindex="-1"></a>rulesFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb398-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb398-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;PART&quot;</span>,</span>
<span id="cb398-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb398-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb398-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb398-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb398-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb398-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index))</span>
<span id="cb398-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb398-6" aria-hidden="true" tabindex="-1"></a>rulesFit</span></code></pre></div>
<pre><code>## Rule-Based Classifier 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 77, 72, 77, 74, 74, 73, ... 
## Resampling results across tuning parameters:
## 
##   threshold  pruned  Accuracy  Kappa
##   0.010      yes     0.965     0.955
##   0.010      no      0.988     0.984
##   0.133      yes     0.965     0.955
##   0.133      no      0.988     0.984
##   0.255      yes     0.965     0.955
##   0.255      no      0.988     0.984
##   0.378      yes     0.965     0.955
##   0.378      no      0.988     0.984
##   0.500      yes     0.965     0.955
##   0.500      no      0.988     0.984
## 
## Accuracy was used to select the optimal model
##  using the largest value.
## The final values used for the model were threshold
##  = 0.5 and pruned = no.</code></pre>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb400-1" aria-hidden="true" tabindex="-1"></a>rulesFit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## PART decision list
## ------------------
## 
## feathersTRUE &lt;= 0 AND
## milkTRUE &gt; 0: mammal (33.0)
## 
## feathersTRUE &gt; 0: bird (16.0)
## 
## toothedTRUE &lt;= 0 AND
## airborneTRUE &lt;= 0 AND
## predatorTRUE &gt; 0: mollusc.et.al (6.0)
## 
## toothedTRUE &lt;= 0 AND
## legs &gt; 2: insect (7.0)
## 
## finsTRUE &gt; 0: fish (11.0)
## 
## toothedTRUE &gt; 0 AND
## aquaticTRUE &lt;= 0: reptile (3.0)
## 
## aquaticTRUE &gt; 0 AND
## venomousTRUE &lt;= 0: amphibian (3.0)
## 
## aquaticTRUE &lt;= 0: mollusc.et.al (2.0)
## 
## : reptile (2.0/1.0)
## 
## Number of Rules  :   9</code></pre>
</div>
<div id="linear-support-vector-machines" class="section level3" number="4.2.5">
<h3><span class="header-section-number">4.2.5</span> Linear Support Vector Machines</h3>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb402-1" aria-hidden="true" tabindex="-1"></a>svmFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span>.,</span>
<span id="cb402-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb402-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;svmLinear&quot;</span>,</span>
<span id="cb402-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb402-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb402-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb402-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb402-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb402-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index))</span>
<span id="cb402-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb402-6" aria-hidden="true" tabindex="-1"></a>svmFit</span></code></pre></div>
<pre><code>## Support Vector Machines with Linear Kernel 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 73, 75, 75, 74, 74, 76, ... 
## Resampling results:
## 
##   Accuracy  Kappa
##   1         1    
## 
## Tuning parameter &#39;C&#39; was held constant at a value of 1</code></pre>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb404-1" aria-hidden="true" tabindex="-1"></a>svmFit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## Support Vector Machine object of class &quot;ksvm&quot; 
## 
## SV type: C-svc  (classification) 
##  parameter : cost C = 1 
## 
## Linear (vanilla) kernel function. 
## 
## Number of Support Vectors : 44 
## 
## Objective Function Value : -0.143 -0.198 -0.148 -0.175 -0.0945 -0.104 -0.19 -0.0814 -0.154 -0.0917 -0.115 -0.177 -0.568 -0.104 -0.15 -0.119 -0.0478 -0.083 -0.123 -0.148 -0.58 
## Training error : 0</code></pre>
</div>
<div id="random-forest" class="section level3" number="4.2.6">
<h3><span class="header-section-number">4.2.6</span> Random Forest</h3>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb406-1" aria-hidden="true" tabindex="-1"></a>randomForestFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb406-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb406-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb406-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb406-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb406-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb406-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb406-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb406-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index))</span>
<span id="cb406-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb406-6" aria-hidden="true" tabindex="-1"></a>randomForestFit</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 74, 76, 75, 74, 73, 76, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa
##    2    0.976     0.968
##    5    0.976     0.968
##    9    0.976     0.968
##   12    0.965     0.954
##   16    0.976     0.969
## 
## Accuracy was used to select the optimal model
##  using the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb408-1" aria-hidden="true" tabindex="-1"></a>randomForestFit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = min(param$mtry, ncol(x))) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 3.61%
## Confusion matrix:
##               mammal bird reptile fish amphibian
## mammal            33    0       0    0         0
## bird               0   16       0    0         0
## reptile            0    0       2    1         1
## fish               0    0       0   11         0
## amphibian          0    0       0    0         4
## insect             0    0       0    0         0
## mollusc.et.al      0    0       0    0         0
##               insect mollusc.et.al class.error
## mammal             0             0       0.000
## bird               0             0       0.000
## reptile            0             0       0.500
## fish               0             0       0.000
## amphibian          0             0       0.000
## insect             7             0       0.000
## mollusc.et.al      1             7       0.125</code></pre>
</div>
<div id="gradient-boosted-decision-trees-xgboost" class="section level3" number="4.2.7">
<h3><span class="header-section-number">4.2.7</span> Gradient Boosted Decision Trees (xgboost)</h3>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-1" aria-hidden="true" tabindex="-1"></a>xgboostFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb410-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;xgbTree&quot;</span>,</span>
<span id="cb410-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb410-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb410-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index),</span>
<span id="cb410-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(</span>
<span id="cb410-7"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">20</span>,</span>
<span id="cb410-8"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="dv">3</span>,</span>
<span id="cb410-9"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">colsample_bytree =</span> .<span class="dv">6</span>,</span>
<span id="cb410-10"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">eta =</span> <span class="fl">0.1</span>,</span>
<span id="cb410-11"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma=</span><span class="dv">0</span>,</span>
<span id="cb410-12"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">min_child_weight =</span> <span class="dv">1</span>,</span>
<span id="cb410-13"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">subsample =</span> .<span class="dv">5</span></span>
<span id="cb410-14"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-14" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb410-15"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb410-15" aria-hidden="true" tabindex="-1"></a>xgboostFit</span></code></pre></div>
<pre><code>## eXtreme Gradient Boosting 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 76, 75, 75, 74, 76, 74, ... 
## Resampling results:
## 
##   Accuracy  Kappa
##   0.976     0.969
## 
## Tuning parameter &#39;nrounds&#39; was held constant at
##  a value of 1
## Tuning parameter &#39;subsample&#39; was
##  held constant at a value of 0.5</code></pre>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb412-1" aria-hidden="true" tabindex="-1"></a>xgboostFit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## ##### xgb.Booster
## raw: 83.5 Kb 
## call:
##   xgboost::xgb.train(params = list(eta = param$eta, max_depth = param$max_depth, 
##     gamma = param$gamma, colsample_bytree = param$colsample_bytree, 
##     min_child_weight = param$min_child_weight, subsample = param$subsample), 
##     data = x, nrounds = param$nrounds, num_class = length(lev), 
##     objective = &quot;multi:softprob&quot;)
## params (as set within xgb.train):
##   eta = &quot;0.1&quot;, max_depth = &quot;3&quot;, gamma = &quot;0&quot;, colsample_bytree = &quot;0.6&quot;, min_child_weight = &quot;1&quot;, subsample = &quot;0.5&quot;, num_class = &quot;7&quot;, objective = &quot;multi:softprob&quot;, validate_parameters = &quot;TRUE&quot;
## xgb.attributes:
##   niter
## callbacks:
##   cb.print.evaluation(period = print_every_n)
## # of features: 16 
## niter: 20
## nfeatures : 16 
## xNames : hairTRUE feathersTRUE eggsTRUE milkTRUE airborneTRUE aquaticTRUE predatorTRUE toothedTRUE backboneTRUE breathesTRUE venomousTRUE finsTRUE legs tailTRUE domesticTRUE catsizeTRUE 
## problemType : Classification 
## tuneValue :
##    nrounds max_depth eta gamma colsample_bytree
## 1      20         3 0.1     0              0.6
##   min_child_weight subsample
## 1                1       0.5
## obsLevels : mammal bird reptile fish amphibian insect mollusc.et.al 
## param :
##  list()</code></pre>
</div>
<div id="artificial-neural-network" class="section level3" number="4.2.8">
<h3><span class="header-section-number">4.2.8</span> Artificial Neural Network</h3>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-1" aria-hidden="true" tabindex="-1"></a>nnetFit <span class="ot">&lt;-</span> Zoo_train <span class="sc">%&gt;%</span> <span class="fu">train</span>(type <span class="sc">~</span> .,</span>
<span id="cb414-2"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;nnet&quot;</span>,</span>
<span id="cb414-3"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> .,</span>
<span id="cb414-4"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb414-5"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">indexOut =</span> train_index),</span>
<span id="cb414-6"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb414-7"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb414-7" aria-hidden="true" tabindex="-1"></a>nnetFit</span></code></pre></div>
<pre><code>## Neural Network 
## 
## 83 samples
## 16 predictors
##  7 classes: &#39;mammal&#39;, &#39;bird&#39;, &#39;reptile&#39;, &#39;fish&#39;, &#39;amphibian&#39;, &#39;insect&#39;, &#39;mollusc.et.al&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 75, 77, 72, 75, 75, 76, ... 
## Resampling results across tuning parameters:
## 
##   size  decay  Accuracy  Kappa
##   1     0e+00  0.694     0.558
##   1     1e-04  0.807     0.728
##   1     1e-03  0.892     0.852
##   1     1e-02  0.825     0.766
##   1     1e-01  0.727     0.633
##   3     0e+00  0.954     0.939
##   3     1e-04  0.989     0.986
##   3     1e-03  0.989     0.986
##   3     1e-02  0.989     0.986
##   3     1e-01  0.989     0.986
##   5     0e+00  0.939     0.917
##   5     1e-04  0.965     0.954
##   5     1e-03  0.989     0.986
##   5     1e-02  0.989     0.986
##   5     1e-01  0.989     0.986
##   7     0e+00  0.989     0.986
##   7     1e-04  0.989     0.986
##   7     1e-03  0.989     0.986
##   7     1e-02  1.000     1.000
##   7     1e-01  0.989     0.986
##   9     0e+00  0.989     0.986
##   9     1e-04  0.989     0.986
##   9     1e-03  0.989     0.986
##   9     1e-02  0.989     0.986
##   9     1e-01  1.000     1.000
## 
## Accuracy was used to select the optimal model
##  using the largest value.
## The final values used for the model were size = 7
##  and decay = 0.01.</code></pre>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="4-2-fitting-different-classification-models-to-the-training-data.html#cb416-1" aria-hidden="true" tabindex="-1"></a>nnetFit<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## a 16-7-7 network with 175 weights
## inputs: hairTRUE feathersTRUE eggsTRUE milkTRUE airborneTRUE aquaticTRUE predatorTRUE toothedTRUE backboneTRUE breathesTRUE venomousTRUE finsTRUE legs tailTRUE domesticTRUE catsizeTRUE 
## output(s): .outcome 
## options were - softmax modelling  decay=0.01</code></pre>
</div>
</div>
<p style="text-align: center;">
<a href="4-1-training-and-test-data.html"><button class="btn btn-default">Previous</button></a>
<a href="4-3-comparing-models.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
