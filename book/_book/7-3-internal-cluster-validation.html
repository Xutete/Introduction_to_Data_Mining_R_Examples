<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.3 Internal Cluster Validation | R Code Companion for the Textbook Introduction to Data Mining" />
<meta property="og:type" content="book" />


<meta property="og:description" content="This book contains documented R examples to accompany several chapters of the popular data mining text book Introduction to Data Mining by Pang-Ning Tan, Michael Steinbach and Vipin Kumar (2006 or 2017 edition)." />


<meta name="author" content="Michael Hahsler" />

<meta name="date" content="2021-07-09" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book contains documented R examples to accompany several chapters of the popular data mining text book Introduction to Data Mining by Pang-Ning Tan, Michael Steinbach and Vipin Kumar (2006 or 2017 edition).">

<title>7.3 Internal Cluster Validation | R Code Companion for the Textbook Introduction to Data Mining</title>

<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap/js/bootstrap.min.js"></script>
<script src="libs/bootstrap/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation/tabsets.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider/jquery.nouislider.min.js"></script>
<link href="libs/selectize/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize/selectize.min.js"></script>
<link href="libs/vis/vis.css" rel="stylesheet" />
<script src="libs/vis/vis.min.js"></script>
<script src="libs/visNetwork-binding/visNetwork.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li><a href="1-introduction.html#introduction"><span class="toc-section-number">1</span> Introduction</a>
<ul>
<li><a href="1-1-data-manipulation-with-tidyverse.html#data-manipulation-with-tidyverse"><span class="toc-section-number">1.1</span> Data Manipulation with Tidyverse</a></li>
<li><a href="1-2-visualization-with-ggplot2.html#visualization-with-ggplot2"><span class="toc-section-number">1.2</span> Visualization with ggplot2</a></li>
</ul></li>
<li><a href="2-data.html#data"><span class="toc-section-number">2</span> Data</a>
<ul>
<li><a href="2-1-the-iris-dataset.html#the-iris-dataset"><span class="toc-section-number">2.1</span> The Iris Dataset</a></li>
<li><a href="2-2-data-quality.html#data-quality"><span class="toc-section-number">2.2</span> Data Quality</a></li>
<li><a href="2-3-aggregation.html#aggregation"><span class="toc-section-number">2.3</span> Aggregation</a></li>
<li><a href="2-4-sampling.html#sampling"><span class="toc-section-number">2.4</span> Sampling</a>
<ul>
<li><a href="2-4-sampling.html#random-sampling"><span class="toc-section-number">2.4.1</span> Random Sampling</a></li>
<li><a href="2-4-sampling.html#stratified-sampling"><span class="toc-section-number">2.4.2</span> Stratified Sampling</a></li>
</ul></li>
<li><a href="2-5-features.html#features"><span class="toc-section-number">2.5</span> Features</a>
<ul>
<li><a href="2-5-features.html#dimensionality-reduction"><span class="toc-section-number">2.5.1</span> Dimensionality Reduction</a></li>
<li><a href="2-5-features.html#feature-selection"><span class="toc-section-number">2.5.2</span> Feature Selection</a></li>
<li><a href="2-5-features.html#discretize-features"><span class="toc-section-number">2.5.3</span> Discretize Features</a></li>
<li><a href="2-5-features.html#standardize-data-z-scores"><span class="toc-section-number">2.5.4</span> Standardize Data (Z-Scores)</a></li>
</ul></li>
<li><a href="2-6-proximities-similarities-and-distances.html#proximities-similarities-and-distances"><span class="toc-section-number">2.6</span> Proximities: Similarities and Distances</a>
<ul>
<li><a href="2-6-proximities-similarities-and-distances.html#minkowsky-distances"><span class="toc-section-number">2.6.1</span> Minkowsky Distances</a></li>
<li><a href="2-6-proximities-similarities-and-distances.html#distances-for-binary-data"><span class="toc-section-number">2.6.2</span> Distances for Binary Data</a></li>
<li><a href="2-6-proximities-similarities-and-distances.html#distances-for-mixed-data"><span class="toc-section-number">2.6.3</span> Distances for Mixed Data</a></li>
<li><a href="2-6-proximities-similarities-and-distances.html#additional-proximity-measures-available-in-package-proxy"><span class="toc-section-number">2.6.4</span> Additional proximity Measures Available in Package proxy</a></li>
</ul></li>
<li><a href="2-7-relationships-between-features.html#relationships-between-features"><span class="toc-section-number">2.7</span> Relationships Between Features</a>
<ul>
<li><a href="2-7-relationships-between-features.html#correlation"><span class="toc-section-number">2.7.1</span> Correlation</a></li>
<li><a href="2-7-relationships-between-features.html#rank-correlation"><span class="toc-section-number">2.7.2</span> Rank Correlation</a></li>
<li><a href="2-7-relationships-between-features.html#relationship-between-nominal-and-ordinal-features"><span class="toc-section-number">2.7.3</span> Relationship Between Nominal and Ordinal Features</a></li>
</ul></li>
<li><a href="2-8-density-estimation.html#density-estimation"><span class="toc-section-number">2.8</span> Density Estimation</a></li>
<li><a href="2-9-exploring-data.html#exploring-data"><span class="toc-section-number">2.9</span> Exploring Data</a>
<ul>
<li><a href="2-9-exploring-data.html#basic-statistics"><span class="toc-section-number">2.9.1</span> Basic statistics</a></li>
<li><a href="2-9-exploring-data.html#tabulate-data"><span class="toc-section-number">2.9.2</span> Tabulate data</a></li>
<li><a href="2-9-exploring-data.html#percentiles-quantiles"><span class="toc-section-number">2.9.3</span> Percentiles (Quantiles)</a></li>
</ul></li>
<li><a href="2-10-visualization.html#visualization"><span class="toc-section-number">2.10</span> Visualization</a>
<ul>
<li><a href="2-10-visualization.html#histogram"><span class="toc-section-number">2.10.1</span> Histogram</a></li>
<li><a href="2-10-visualization.html#boxplot"><span class="toc-section-number">2.10.2</span> Boxplot</a></li>
<li><a href="2-10-visualization.html#scatter-plot"><span class="toc-section-number">2.10.3</span> Scatter plot</a></li>
<li><a href="2-10-visualization.html#scatter-plot-matrix"><span class="toc-section-number">2.10.4</span> Scatter Plot Matrix</a></li>
<li><a href="2-10-visualization.html#data-matrix-visualization"><span class="toc-section-number">2.10.5</span> Data Matrix Visualization</a></li>
<li><a href="2-10-visualization.html#correlation-matrix"><span class="toc-section-number">2.10.6</span> Correlation Matrix</a></li>
<li><a href="2-10-visualization.html#parallel-coordinates-plot"><span class="toc-section-number">2.10.7</span> Parallel Coordinates Plot</a></li>
</ul></li>
</ul></li>
<li><a href="3-classification-basic-concepts-and-techniques.html#classification-basic-concepts-and-techniques"><span class="toc-section-number">3</span> Classification: Basic Concepts and Techniques</a>
<ul>
<li><a href="3-1-the-zoo-dataset.html#the-zoo-dataset"><span class="toc-section-number">3.1</span> The Zoo Dataset</a></li>
<li><a href="3-2-decision-trees.html#decision-trees"><span class="toc-section-number">3.2</span> Decision Trees</a>
<ul>
<li><a href="3-2-decision-trees.html#create-tree-with-default-settings-uses-pre-pruning"><span class="toc-section-number">3.2.1</span> Create Tree With Default Settings (uses pre-pruning)</a></li>
<li><a href="3-2-decision-trees.html#create-a-full-tree"><span class="toc-section-number">3.2.2</span> Create a Full Tree</a></li>
<li><a href="3-2-decision-trees.html#make-predictions-for-new-data"><span class="toc-section-number">3.2.3</span> Make Predictions for New Data</a></li>
</ul></li>
<li><a href="3-3-model-evaluation-with-caret.html#model-evaluation-with-caret"><span class="toc-section-number">3.3</span> Model Evaluation with Caret</a>
<ul>
<li><a href="3-3-model-evaluation-with-caret.html#hold-out-test-data"><span class="toc-section-number">3.3.1</span> Hold out Test Data</a></li>
<li><a href="3-3-model-evaluation-with-caret.html#learn-a-model-and-tune-hyperparameters-on-the-training-data"><span class="toc-section-number">3.3.2</span> Learn a Model and Tune Hyperparameters on the Training Data</a></li>
</ul></li>
<li><a href="3-4-testing-confusion-matrix-and-confidence-interval-for-accuracy.html#testing-confusion-matrix-and-confidence-interval-for-accuracy"><span class="toc-section-number">3.4</span> Testing: Confusion Matrix and Confidence Interval for Accuracy</a></li>
<li><a href="3-5-model-comparison.html#model-comparison"><span class="toc-section-number">3.5</span> Model Comparison</a></li>
<li><a href="3-6-feature-selection-and-feature-preparation.html#feature-selection-and-feature-preparation"><span class="toc-section-number">3.6</span> Feature Selection and Feature Preparation</a>
<ul>
<li><a href="3-6-feature-selection-and-feature-preparation.html#univariate-feature-importance-score"><span class="toc-section-number">3.6.1</span> Univariate Feature Importance Score</a></li>
<li><a href="3-6-feature-selection-and-feature-preparation.html#feature-subset-selection"><span class="toc-section-number">3.6.2</span> Feature Subset Selection</a></li>
<li><a href="3-6-feature-selection-and-feature-preparation.html#using-dummy-variables-for-factors"><span class="toc-section-number">3.6.3</span> Using Dummy Variables for Factors</a></li>
</ul></li>
<li><a href="3-7-class-imbalance.html#class-imbalance"><span class="toc-section-number">3.7</span> Class Imbalance</a>
<ul>
<li><a href="3-7-class-imbalance.html#option-1-use-the-data-as-is-and-hope-for-the-best"><span class="toc-section-number">3.7.1</span> Option 1: Use the Data As Is and Hope For The Best</a></li>
<li><a href="3-7-class-imbalance.html#option-2-balance-data-with-resampling"><span class="toc-section-number">3.7.2</span> Option 2: Balance Data With Resampling</a></li>
<li><a href="3-7-class-imbalance.html#option-3-build-a-larger-tree-and-use-predicted-probabilities"><span class="toc-section-number">3.7.3</span> Option 3: Build A Larger Tree and use Predicted Probabilities</a></li>
<li><a href="3-7-class-imbalance.html#option-4-use-a-cost-sensitive-classifier"><span class="toc-section-number">3.7.4</span> Option 4: Use a Cost-Sensitive Classifier</a></li>
</ul></li>
</ul></li>
<li><a href="4-classification-alternative-techniques.html#classification-alternative-techniques"><span class="toc-section-number">4</span> Classification: Alternative Techniques</a>
<ul>
<li><a href="4-1-training-and-test-data.html#training-and-test-data"><span class="toc-section-number">4.1</span> Training and Test Data</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#fitting-different-classification-models-to-the-training-data"><span class="toc-section-number">4.2</span> Fitting Different Classification Models to the Training Data</a>
<ul>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#conditional-inference-tree-decision-tree"><span class="toc-section-number">4.2.1</span> Conditional Inference Tree (Decision Tree)</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#c-4.5-decision-tree"><span class="toc-section-number">4.2.2</span> C 4.5 Decision Tree</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#k-nearest-neighbors"><span class="toc-section-number">4.2.3</span> K-Nearest Neighbors</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#part-rule-based-classifier"><span class="toc-section-number">4.2.4</span> PART (Rule-based classifier)</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#linear-support-vector-machines"><span class="toc-section-number">4.2.5</span> Linear Support Vector Machines</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#random-forest"><span class="toc-section-number">4.2.6</span> Random Forest</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#gradient-boosted-decision-trees-xgboost"><span class="toc-section-number">4.2.7</span> Gradient Boosted Decision Trees (xgboost)</a></li>
<li><a href="4-2-fitting-different-classification-models-to-the-training-data.html#artificial-neural-network"><span class="toc-section-number">4.2.8</span> Artificial Neural Network</a></li>
</ul></li>
<li><a href="4-3-comparing-models.html#comparing-models"><span class="toc-section-number">4.3</span> Comparing Models</a></li>
<li><a href="4-4-applying-the-chosen-model-to-the-test-data.html#applying-the-chosen-model-to-the-test-data"><span class="toc-section-number">4.4</span> Applying the Chosen Model to the Test Data</a></li>
<li><a href="4-5-decision-boundaries.html#decision-boundaries"><span class="toc-section-number">4.5</span> Decision Boundaries</a>
<ul>
<li><a href="4-5-decision-boundaries.html#iris-dataset"><span class="toc-section-number">4.5.1</span> Iris Dataset</a></li>
<li><a href="4-5-decision-boundaries.html#circle-dataset"><span class="toc-section-number">4.5.2</span> Circle Dataset</a></li>
</ul></li>
<li><a href="4-6-more-information.html#more-information"><span class="toc-section-number">4.6</span> More Information</a></li>
</ul></li>
<li><a href="5-association-analysis-basic-concepts-and-algorithms.html#association-analysis-basic-concepts-and-algorithms"><span class="toc-section-number">5</span> Association Analysis: Basic Concepts and Algorithms</a>
<ul>
<li><a href="5-1-the-arules-package.html#the-arules-package"><span class="toc-section-number">5.1</span> The arules Package</a></li>
<li><a href="5-2-transactions.html#transactions"><span class="toc-section-number">5.2</span> Transactions</a>
<ul>
<li><a href="5-2-transactions.html#create-transactions"><span class="toc-section-number">5.2.1</span> Create Transactions</a></li>
<li><a href="5-2-transactions.html#inspect-transactions"><span class="toc-section-number">5.2.2</span> Inspect Transactions</a></li>
<li><a href="5-2-transactions.html#vertical-layout-transaction-id-lists"><span class="toc-section-number">5.2.3</span> Vertical Layout (Transaction ID Lists)</a></li>
</ul></li>
<li><a href="5-3-frequent-itemsets.html#frequent-itemsets"><span class="toc-section-number">5.3</span> Frequent Itemsets</a>
<ul>
<li><a href="5-3-frequent-itemsets.html#mine-frequent-itemsets"><span class="toc-section-number">5.3.1</span> Mine Frequent Itemsets</a></li>
<li><a href="5-3-frequent-itemsets.html#concise-representation-of-itemsets"><span class="toc-section-number">5.3.2</span> Concise Representation of Itemsets</a></li>
</ul></li>
<li><a href="5-4-association-rules.html#association-rules"><span class="toc-section-number">5.4</span> Association Rules</a>
<ul>
<li><a href="5-4-association-rules.html#mine-association-rules"><span class="toc-section-number">5.4.1</span> Mine Association Rules</a></li>
<li><a href="5-4-association-rules.html#calculate-additional-interest-measures"><span class="toc-section-number">5.4.2</span> Calculate Additional Interest Measures</a></li>
<li><a href="5-4-association-rules.html#mine-using-templates"><span class="toc-section-number">5.4.3</span> Mine Using Templates</a></li>
</ul></li>
<li><a href="5-5-association-rule-visualization.html#association-rule-visualization"><span class="toc-section-number">5.5</span> Association Rule Visualization</a></li>
<li><a href="5-6-interactive-visualizations.html#interactive-visualizations"><span class="toc-section-number">5.6</span> Interactive Visualizations</a>
<ul>
<li><a href="5-6-interactive-visualizations.html#interactive-inspect-with-sorting-filtering-and-paging"><span class="toc-section-number">5.6.1</span> Interactive Inspect With Sorting, Filtering and Paging</a></li>
<li><a href="5-6-interactive-visualizations.html#scatter-plot-1"><span class="toc-section-number">5.6.2</span> Scatter Plot</a></li>
<li><a href="5-6-interactive-visualizations.html#matrix-visualization"><span class="toc-section-number">5.6.3</span> Matrix Visualization</a></li>
<li><a href="5-6-interactive-visualizations.html#visualization-as-graph"><span class="toc-section-number">5.6.4</span> Visualization as Graph</a></li>
<li><a href="5-6-interactive-visualizations.html#interactive-rule-explorer"><span class="toc-section-number">5.6.5</span> Interactive Rule Explorer</a></li>
</ul></li>
</ul></li>
<li><a href="6-association-analysis-advanced-concepts.html#association-analysis-advanced-concepts"><span class="toc-section-number">6</span> Association Analysis: Advanced Concepts</a></li>
<li><a href="7-clustering-analysis.html#clustering-analysis"><span class="toc-section-number">7</span> Clustering Analysis</a>
<ul>
<li><a href="7-1-data-preparation.html#data-preparation"><span class="toc-section-number">7.1</span> Data Preparation</a>
<ul>
<li><a href="7-1-data-preparation.html#data-cleaning"><span class="toc-section-number">7.1.1</span> Data cleaning</a></li>
<li><a href="7-1-data-preparation.html#scale-data"><span class="toc-section-number">7.1.2</span> Scale data</a></li>
</ul></li>
<li><a href="7-2-clustering-methods.html#clustering-methods"><span class="toc-section-number">7.2</span> Clustering methods</a>
<ul>
<li><a href="7-2-clustering-methods.html#k-means-clustering"><span class="toc-section-number">7.2.1</span> k-means Clustering</a></li>
<li><a href="7-2-clustering-methods.html#hierarchical-clustering"><span class="toc-section-number">7.2.2</span> Hierarchical Clustering</a></li>
<li><a href="7-2-clustering-methods.html#density-based-clustering-with-dbscan"><span class="toc-section-number">7.2.3</span> Density-based clustering with DBSCAN</a></li>
<li><a href="7-2-clustering-methods.html#partitioning-around-medoids-pam"><span class="toc-section-number">7.2.4</span> Partitioning Around Medoids (PAM)</a></li>
<li><a href="7-2-clustering-methods.html#gaussian-mixture-models"><span class="toc-section-number">7.2.5</span> Gaussian Mixture Models</a></li>
<li><a href="7-2-clustering-methods.html#spectral-clustering"><span class="toc-section-number">7.2.6</span> Spectral clustering</a></li>
<li><a href="7-2-clustering-methods.html#fuzzy-c-means-clustering"><span class="toc-section-number">7.2.7</span> Fuzzy C-Means Clustering</a></li>
</ul></li>
<li><a href="7-3-internal-cluster-validation.html#internal-cluster-validation"><span class="toc-section-number">7.3</span> Internal Cluster Validation</a>
<ul>
<li><a href="7-3-internal-cluster-validation.html#compare-the-clustering-quality"><span class="toc-section-number">7.3.1</span> Compare the Clustering Quality</a></li>
<li><a href="7-3-internal-cluster-validation.html#silhouette-plot"><span class="toc-section-number">7.3.2</span> Silhouette plot</a></li>
<li><a href="7-3-internal-cluster-validation.html#find-optimal-number-of-clusters-for-k-means"><span class="toc-section-number">7.3.3</span> Find Optimal Number of Clusters for k-means</a></li>
<li><a href="7-3-internal-cluster-validation.html#visualizing-the-distance-matrix"><span class="toc-section-number">7.3.4</span> Visualizing the Distance Matrix</a></li>
</ul></li>
<li><a href="7-4-external-cluster-validation.html#external-cluster-validation"><span class="toc-section-number">7.4</span> External Cluster Validation</a></li>
<li><a href="7-5-advanced-data-preparation-for-clustering.html#advanced-data-preparation-for-clustering"><span class="toc-section-number">7.5</span> Advanced Data Preparation for Clustering</a>
<ul>
<li><a href="7-5-advanced-data-preparation-for-clustering.html#outlier-removal"><span class="toc-section-number">7.5.1</span> Outlier Removal</a></li>
<li><a href="7-5-advanced-data-preparation-for-clustering.html#clustering-tendency"><span class="toc-section-number">7.5.2</span> Clustering Tendency</a></li>
</ul></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="internal-cluster-validation" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Internal Cluster Validation</h2>
<div id="compare-the-clustering-quality" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Compare the Clustering Quality</h3>
<p>The two most popular quality metrics are the within-cluster sum of squares (WCSS) used
by <a href="https://en.wikipedia.org/wiki/K-means_clustering"><span class="math inline">\(k\)</span>-means</a> and
the <a href="https://en.wikipedia.org/wiki/Silhouette_(clustering)">average silhouette width</a>.
Look at <code>within.cluster.ss</code> and <code>avg.silwidth</code> below.</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="7-3-internal-cluster-validation.html#cb728-1" aria-hidden="true" tabindex="-1"></a><span class="do">##library(fpc)</span></span></code></pre></div>
<p>Notes:
* I do not load fpc since the NAMESPACE overwrites dbscan.
* The clustering (second argument below) has to be supplied as a vector with numbers (cluster IDs) and cannot be a factor (use <code>as.integer()</code> to convert the factor to an ID).</p>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="7-3-internal-cluster-validation.html#cb729-1" aria-hidden="true" tabindex="-1"></a>fpc<span class="sc">::</span><span class="fu">cluster.stats</span>(d, km<span class="sc">$</span>cluster)</span></code></pre></div>
<pre><code>## $n
## [1] 75
## 
## $cluster.number
## [1] 4
## 
## $cluster.size
## [1] 17 23 15 20
## 
## $min.cluster.size
## [1] 15
## 
## $noisen
## [1] 0
## 
## $diameter
## [1] 1.463 1.159 0.836 1.119
## 
## $average.distance
## [1] 0.581 0.429 0.356 0.482
## 
## $median.distance
## [1] 0.502 0.393 0.338 0.449
## 
## $separation
## [1] 0.768 0.768 1.158 1.158
## 
## $average.toother
## [1] 2.29 2.15 2.31 2.16
## 
## $separation.matrix
##       [,1]  [,2] [,3] [,4]
## [1,] 0.000 0.768 1.31 1.34
## [2,] 0.768 0.000 1.96 1.22
## [3,] 1.308 1.958 0.00 1.16
## [4,] 1.340 1.220 1.16 0.00
## 
## $ave.between.matrix
##      [,1] [,2] [,3] [,4]
## [1,] 0.00 1.92 2.22 2.77
## [2,] 1.92 0.00 2.75 1.89
## [3,] 2.22 2.75 0.00 1.87
## [4,] 2.77 1.89 1.87 0.00
## 
## $average.between
## [1] 2.22
## 
## $average.within
## [1] 0.463
## 
## $n.between
## [1] 2091
## 
## $n.within
## [1] 684
## 
## $max.diameter
## [1] 1.46
## 
## $min.separation
## [1] 0.768
## 
## $within.cluster.ss
## [1] 10.1
## 
## $clus.avg.silwidths
##     1     2     3     4 
## 0.681 0.745 0.807 0.721 
## 
## $avg.silwidth
## [1] 0.737
## 
## $g2
## NULL
## 
## $g3
## NULL
## 
## $pearsongamma
## [1] 0.842
## 
## $dunn
## [1] 0.525
## 
## $dunn2
## [1] 3.23
## 
## $entropy
## [1] 1.37
## 
## $wb.ratio
## [1] 0.209
## 
## $ch
## [1] 324
## 
## $cwidegap
## [1] 0.415 0.315 0.235 0.261
## 
## $widestgap
## [1] 0.415
## 
## $sindex
## [1] 0.858
## 
## $corrected.rand
## NULL
## 
## $vi
## NULL</code></pre>
<p>Read <code>? cluster.stats</code> for an explanation of all the available indices.</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="7-3-internal-cluster-validation.html#cb731-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(</span>
<span id="cb731-2"><a href="7-3-internal-cluster-validation.html#cb731-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb731-3"><a href="7-3-internal-cluster-validation.html#cb731-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">km =</span> km<span class="sc">$</span>cluster,</span>
<span id="cb731-4"><a href="7-3-internal-cluster-validation.html#cb731-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">hc_compl =</span> <span class="fu">cutree</span>(hc, <span class="at">k =</span> <span class="dv">4</span>),</span>
<span id="cb731-5"><a href="7-3-internal-cluster-validation.html#cb731-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">hc_single =</span> <span class="fu">cutree</span>(hc_single, <span class="at">k =</span> <span class="dv">4</span>)</span>
<span id="cb731-6"><a href="7-3-internal-cluster-validation.html#cb731-6" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb731-7"><a href="7-3-internal-cluster-validation.html#cb731-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> <span class="cf">function</span>(x)</span>
<span id="cb731-8"><a href="7-3-internal-cluster-validation.html#cb731-8" aria-hidden="true" tabindex="-1"></a>    fpc<span class="sc">::</span><span class="fu">cluster.stats</span>(d, x))[<span class="fu">c</span>(<span class="st">&quot;within.cluster.ss&quot;</span>, <span class="st">&quot;avg.silwidth&quot;</span>), ]</span></code></pre></div>
<pre><code>##                   km    hc_compl hc_single
## within.cluster.ss 10.1  10.1     10.1     
## avg.silwidth      0.737 0.737    0.737</code></pre>
</div>
<div id="silhouette-plot" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Silhouette plot</h3>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="7-3-internal-cluster-validation.html#cb733-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb733-2"><a href="7-3-internal-cluster-validation.html#cb733-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">silhouette</span>(km<span class="sc">$</span>cluster, d))</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-264-1.png" width="672" /></p>
<p><strong>Note:</strong> The silhouette plot does not show correctly in R Studio if you have too many objects (bars are missing). I will work when you open a new plotting device with <code>windows()</code>, <code>x11()</code> or <code>quartz()</code>.</p>
<p>ggplot visualization using <code>factoextra</code></p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="7-3-internal-cluster-validation.html#cb734-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_silhouette</span>(<span class="fu">silhouette</span>(km<span class="sc">$</span>cluster, d))</span></code></pre></div>
<pre><code>##   cluster size ave.sil.width
## 1       1   17          0.68
## 2       2   23          0.75
## 3       3   15          0.81
## 4       4   20          0.72</code></pre>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-265-1.png" width="672" /></p>
</div>
<div id="find-optimal-number-of-clusters-for-k-means" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Find Optimal Number of Clusters for k-means</h3>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="7-3-internal-cluster-validation.html#cb736-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ruspini_scaled, <span class="fu">aes</span>(x, y)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-266-1.png" width="672" /></p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="7-3-internal-cluster-validation.html#cb737-1" aria-hidden="true" tabindex="-1"></a><span class="do">## We will use different methods and try 1-10 clusters.</span></span>
<span id="cb737-2"><a href="7-3-internal-cluster-validation.html#cb737-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb737-3"><a href="7-3-internal-cluster-validation.html#cb737-3" aria-hidden="true" tabindex="-1"></a>ks <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">10</span></span></code></pre></div>
<div id="elbow-method-within-cluster-sum-of-squares" class="section level4" number="7.3.3.1">
<h4><span class="header-section-number">7.3.3.1</span> Elbow Method: Within-Cluster Sum of Squares</h4>
<p>Calculate the within-cluster sum of squares for different numbers of clusters and look for the <a href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)">knee or elbow</a> in the plot.
(<code>nstart = 5</code> just repeats k-means 5 times and returns the best solution)</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="7-3-internal-cluster-validation.html#cb738-1" aria-hidden="true" tabindex="-1"></a>WCSS <span class="ot">&lt;-</span> <span class="fu">sapply</span>(ks, <span class="at">FUN =</span> <span class="cf">function</span>(k) {</span>
<span id="cb738-2"><a href="7-3-internal-cluster-validation.html#cb738-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kmeans</span>(ruspini_scaled, <span class="at">centers =</span> k, <span class="at">nstart =</span> <span class="dv">5</span>)<span class="sc">$</span>tot.withinss</span>
<span id="cb738-3"><a href="7-3-internal-cluster-validation.html#cb738-3" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb738-4"><a href="7-3-internal-cluster-validation.html#cb738-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb738-5"><a href="7-3-internal-cluster-validation.html#cb738-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">as_tibble</span>(ks, WCSS), <span class="fu">aes</span>(ks, WCSS)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb738-6"><a href="7-3-internal-cluster-validation.html#cb738-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">4</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-267-1.png" width="672" /></p>
</div>
<div id="average-silhouette-width" class="section level4" number="7.3.3.2">
<h4><span class="header-section-number">7.3.3.2</span> Average Silhouette Width</h4>
<p>Plot the average silhouette width for different number of clusters and look for the maximum in the plot.</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="7-3-internal-cluster-validation.html#cb739-1" aria-hidden="true" tabindex="-1"></a>ASW <span class="ot">&lt;-</span> <span class="fu">sapply</span>(ks, <span class="at">FUN=</span><span class="cf">function</span>(k) {</span>
<span id="cb739-2"><a href="7-3-internal-cluster-validation.html#cb739-2" aria-hidden="true" tabindex="-1"></a>  fpc<span class="sc">::</span><span class="fu">cluster.stats</span>(d, <span class="fu">kmeans</span>(ruspini_scaled, <span class="at">centers=</span>k, <span class="at">nstart =</span> <span class="dv">5</span>)<span class="sc">$</span>cluster)<span class="sc">$</span>avg.silwidth</span>
<span id="cb739-3"><a href="7-3-internal-cluster-validation.html#cb739-3" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb739-4"><a href="7-3-internal-cluster-validation.html#cb739-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb739-5"><a href="7-3-internal-cluster-validation.html#cb739-5" aria-hidden="true" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> ks[<span class="fu">which.max</span>(ASW)]</span>
<span id="cb739-6"><a href="7-3-internal-cluster-validation.html#cb739-6" aria-hidden="true" tabindex="-1"></a>best_k</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="7-3-internal-cluster-validation.html#cb741-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">as_tibble</span>(ks, ASW), <span class="fu">aes</span>(ks, ASW)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb741-2"><a href="7-3-internal-cluster-validation.html#cb741-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> best_k, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-268-1.png" width="672" /></p>
</div>
<div id="dunn-index" class="section level4" number="7.3.3.3">
<h4><span class="header-section-number">7.3.3.3</span> Dunn Index</h4>
<p>Use <a href="https://en.wikipedia.org/wiki/Dunn_index">Dunn index</a> (another internal measure given by min. separation/ max. diameter)</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="7-3-internal-cluster-validation.html#cb742-1" aria-hidden="true" tabindex="-1"></a>DI <span class="ot">&lt;-</span> <span class="fu">sapply</span>(ks, <span class="at">FUN=</span><span class="cf">function</span>(k) {</span>
<span id="cb742-2"><a href="7-3-internal-cluster-validation.html#cb742-2" aria-hidden="true" tabindex="-1"></a>  fpc<span class="sc">::</span><span class="fu">cluster.stats</span>(d, <span class="fu">kmeans</span>(ruspini_scaled, <span class="at">centers=</span>k, <span class="at">nstart=</span><span class="dv">5</span>)<span class="sc">$</span>cluster)<span class="sc">$</span>dunn</span>
<span id="cb742-3"><a href="7-3-internal-cluster-validation.html#cb742-3" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb742-4"><a href="7-3-internal-cluster-validation.html#cb742-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb742-5"><a href="7-3-internal-cluster-validation.html#cb742-5" aria-hidden="true" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> ks[<span class="fu">which.max</span>(DI)]</span>
<span id="cb742-6"><a href="7-3-internal-cluster-validation.html#cb742-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">as_tibble</span>(ks, DI), <span class="fu">aes</span>(ks, DI)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb742-7"><a href="7-3-internal-cluster-validation.html#cb742-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> best_k, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-269-1.png" width="672" /></p>
</div>
<div id="gap-statistic" class="section level4" number="7.3.3.4">
<h4><span class="header-section-number">7.3.3.4</span> Gap Statistic</h4>
<p>Compares the change in within-cluster dispersion with that expected
from a null model (see <code>? clusGap</code>).
The default method is to
choose the smallest k such that its value Gap(k) is not more
than 1 standard error away from the first local maximum.</p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="7-3-internal-cluster-validation.html#cb743-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb743-2"><a href="7-3-internal-cluster-validation.html#cb743-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">clusGap</span>(ruspini_scaled, <span class="at">FUN =</span> kmeans,  <span class="at">nstart =</span> <span class="dv">10</span>, <span class="at">K.max =</span> <span class="dv">10</span>)</span>
<span id="cb743-3"><a href="7-3-internal-cluster-validation.html#cb743-3" aria-hidden="true" tabindex="-1"></a>k</span></code></pre></div>
<pre><code>## Clustering Gap statistic [&quot;clusGap&quot;] from call:
## clusGap(x = ruspini_scaled, FUNcluster = kmeans, K.max = 10,     nstart = 10)
## B=100 simulated reference sets, k = 1..10; spaceH0=&quot;scaledPCA&quot;
##  --&gt; Number of clusters (method &#39;firstSEmax&#39;, SE.factor=1): 4
##       logW E.logW     gap SE.sim
##  [1,] 3.50   3.47 -0.0308 0.0357
##  [2,] 3.07   3.15  0.0762 0.0374
##  [3,] 2.68   2.90  0.2247 0.0380
##  [4,] 2.11   2.70  0.5971 0.0363
##  [5,] 1.99   2.57  0.5827 0.0347
##  [6,] 1.86   2.45  0.5871 0.0365
##  [7,] 1.73   2.35  0.6156 0.0395
##  [8,] 1.66   2.26  0.5987 0.0413
##  [9,] 1.61   2.17  0.5630 0.0409
## [10,] 1.50   2.09  0.5910 0.0393</code></pre>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb745-1"><a href="7-3-internal-cluster-validation.html#cb745-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k)</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-270-1.png" width="672" /></p>
<p><strong>Note:</strong> these methods can also be used for hierarchical clustering.</p>
<p>There have been many other methods and indices proposed to determine
the number of clusters.
See, e.g., package <a href="https://cran.r-project.org/package=NbClust">NbClust</a>.</p>
</div>
</div>
<div id="visualizing-the-distance-matrix" class="section level3" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> Visualizing the Distance Matrix</h3>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="7-3-internal-cluster-validation.html#cb746-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ruspini_scaled, <span class="fu">aes</span>(x, y, <span class="at">color =</span> <span class="fu">factor</span>(km<span class="sc">$</span>cluster))) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-271-1.png" width="672" /></p>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb747-1"><a href="7-3-internal-cluster-validation.html#cb747-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">dist</span>(ruspini_scaled)</span></code></pre></div>
<p>Inspect the distance matrix between the first 5 objects.</p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="7-3-internal-cluster-validation.html#cb748-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(d)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>##      1     2     3     4     5
## 1 0.00 1.887 1.511 3.041 2.978
## 2 1.89 0.000 0.522 1.640 1.746
## 3 1.51 0.522 0.000 2.131 2.207
## 4 3.04 1.640 2.131 0.000 0.282
## 5 2.98 1.746 2.207 0.282 0.000</code></pre>
<p>A false-color image visualizes each value in the matrix as a pixel with the color representing the value.</p>
<div class="sourceCode" id="cb750"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb750-1"><a href="7-3-internal-cluster-validation.html#cb750-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(seriation)</span>
<span id="cb750-2"><a href="7-3-internal-cluster-validation.html#cb750-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pimage</span>(d, <span class="at">col =</span> <span class="fu">bluered</span>(<span class="dv">100</span>))</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-273-1.png" width="672" /></p>
<p>Rows and columns are the objects as they are ordered in the data set. The diagonal represents the distance between an object and itself and has by definition a distance of 0 (dark line).
Visualizing the unordered distance matrix does not show much structure, but we can reorder
the matrix (rows and columns) using the k-means cluster labels from cluster 1 to 4. A clear block structure representing the clusters becomes visible.</p>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="7-3-internal-cluster-validation.html#cb751-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pimage</span>(d, <span class="at">order=</span><span class="fu">order</span>(km<span class="sc">$</span>cluster), <span class="at">col =</span> <span class="fu">bluered</span>(<span class="dv">100</span>))</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-274-1.png" width="672" /></p>
<p>Plot function <code>dissplot</code> in package <strong>seriation</strong> rearranges the matrix and adds lines and cluster labels. In the lower half of the plot, it shows average dissimilarities between clusters. The function
organizes the objects by cluster and then reorders clusters and objects within clusters so that more similar objects are closer together.</p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb752-1"><a href="7-3-internal-cluster-validation.html#cb752-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dissplot</span>(d, <span class="at">labels =</span> km<span class="sc">$</span>cluster, <span class="at">options=</span><span class="fu">list</span>(<span class="at">main=</span><span class="st">&quot;k-means with k=4&quot;</span>))</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-275-1.png" width="672" /></p>
<p>The reordering by <code>dissplot</code> makes the misspecification of k visible as blocks.</p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="7-3-internal-cluster-validation.html#cb753-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dissplot</span>(d, <span class="at">labels =</span> <span class="fu">kmeans</span>(ruspini_scaled, <span class="at">centers =</span> <span class="dv">3</span>)<span class="sc">$</span>cluster, <span class="at">col =</span> <span class="fu">bluered</span>(<span class="dv">100</span>))</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-276-1.png" width="672" /></p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb754-1"><a href="7-3-internal-cluster-validation.html#cb754-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dissplot</span>(d, <span class="at">labels =</span> <span class="fu">kmeans</span>(ruspini_scaled, <span class="at">centers =</span> <span class="dv">9</span>)<span class="sc">$</span>cluster, <span class="at">col =</span> <span class="fu">bluered</span>(<span class="dv">100</span>))</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-276-2.png" width="672" /></p>
<p>Using <code>factoextra</code></p>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="7-3-internal-cluster-validation.html#cb755-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dist</span>(d)</span></code></pre></div>
<p><img src="R-Code-Companion-for-Introduction-to-Data-Mining_files/figure-html/unnamed-chunk-277-1.png" width="672" /></p>
</div>
</div>
<p style="text-align: center;">
<a href="7-2-clustering-methods.html"><button class="btn btn-default">Previous</button></a>
<a href="7-4-external-cluster-validation.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
